from pathlib import Path
import queue
import time

import streamlit as st
from streamlit_webrtc import WebRtcMode, webrtc_streamer

import openai
import pydub
from moviepy.editor import VideoFileClip
from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv())


PASTA_TEMP = Path(__file__).parent / 'temp'
PASTA_TEMP.mkdir(exist_ok=True)
ARQUIVO_AUDIO_TEMP = PASTA_TEMP / 'audio.mp3'
ARQUIVO_VIDEO_TEMP = PASTA_TEMP / 'video.mp4'
ARQUIVO_MIC_TEMP = PASTA_TEMP / 'mic.mp3'

client = openai.OpenAI()

def transcreve_audio(caminho_audio, prompt):
    with open(caminho_audio, 'rb') as arquivo_audio:
        transcricao = client.audio.transcriptions.create(
            model='whisper-1',
            language='pt',
            response_format='text',
            file=arquivo_audio,
            prompt=prompt,
        )
        return transcricao

if not 'transcricao_mic' in st.session_state:
    st.session_state['transcricao_mic'] = ''

@st.cache_data
def get_ice_servers():
    return [{'urls': ['stun:stun.l.google.com:19302']}]


def adiciona_chunck_de_audio(frames_de_audio, chunck_audio):
    for frame in frames_de_audio:
        sound = pydub.AudioSegment(
            data=frame.to_ndarray().tobytes(),
            sample_width=frame.format.bytes,
            frame_rate=frame.sample_rate,
            channels=len(frame.layout.channels)
        )
        chunck_audio += sound
    return chunck_audio

def transcreve_tab_mic():

    #gambiarra feita para possibilitar o deploy da aplica√ß√£o
    if st.button('Start', type='primary'):
        st.warning('O Web app est√° desabilitado por aus√™ncia de chave da OpenAI')
    
    #c√≥digo original comentado abaixo. Removemos ele para o deploy ocorrer sem erros, pois esta parte do c√≥digo realiza conexao com a API da OpenAI 
    #a partir de uma chave, mas como no deploy a chave n√£o √© inserida, por quest√£o de seguran√ßa, precisamos retirar essa parte do c√≥digo e incluir a gambiarra
    #acima para representar o bot√£o original da aplica√ß√£o, mas com aviso informando ao ser clicado que a aplica√ß√£o est√° sem a chave da API.


    # prompt_mic = st.text_input('(opcional) Digite o seu prompt', key='input_mic')
    # webrtx_ctx = webrtc_streamer(
    #     key='recebe_audio',
    #     mode=WebRtcMode.SENDONLY,
    #     audio_receiver_size=1024,
    #     media_stream_constraints={'video': False, 'audio':True}
    # )


    # if not webrtx_ctx.state.playing:
    #     st.write(st.session_state['transcricao_mic'])
    #     return
    
    # container = st.empty()
    # container.markdown('Comece a falar...')
    # chunck_audio = pydub.AudioSegment.empty()
    # tempo_ultima_transcricao = time.time()
    # st.session_state['transcricao_mic'] = ''
    # while True:
    #     if webrtx_ctx.audio_receiver:
    #         try:
    #             frames_de_audio = webrtx_ctx.audio_receiver.get_frames(timeout=1)
    #         except queue.Empty:
    #             time.sleep(0.1)
    #             continue
    #         chunck_audio = adiciona_chunck_de_audio(frames_de_audio, chunck_audio)

    #         agora = time.time()
    #         if len(chunck_audio) > 0 and agora - tempo_ultima_transcricao > 10:
    #             tempo_ultima_transcricao = agora
    #             chunck_audio.export(ARQUIVO_MIC_TEMP)
    #             transcricao = transcreve_audio(ARQUIVO_MIC_TEMP, prompt_mic)
    #             st.session_state['transcricao_mic'] += transcricao
    #             container.write(st.session_state['transcricao_mic'])
    #             chunck_audio = pydub.AudioSegment.empty()
    #     else:
    #         break


# TRANSCREVE VIDEO =====================================
def _salva_audio_do_video(video_bytes):
    with open(ARQUIVO_VIDEO_TEMP, mode='wb') as video_f:
        video_f.write(video_bytes.read())
    moviepy_video = VideoFileClip(str(ARQUIVO_VIDEO_TEMP))
    moviepy_video.audio.write_audiofile(str(ARQUIVO_AUDIO_TEMP))

def transcreve_tab_video():
    prompt_input = st.text_input('(opcional) Digite o seu prompt', key='input_video')
    arquivo_video = st.file_uploader('Adicione um arquivo de v√≠deo .mp4', type=['mp4'])
    if not arquivo_video is None:
        _salva_audio_do_video(arquivo_video)
        transcricao = transcreve_audio(ARQUIVO_AUDIO_TEMP, prompt_input)
        st.write(transcricao)

# TRANSCREVE AUDIO =====================================
def transcreve_tab_audio():
    prompt_input = st.text_input('(opcional) Digite o seu prompt', key='input_audio')
    arquivo_audio = st.file_uploader('Adicione um arquivo de √°udio .mp3', type=['mp3'])
    if not arquivo_audio is None:
        transcricao = client.audio.transcriptions.create(
            model='whisper-1',
            language='pt',
            response_format='text',
            file=arquivo_audio,
            prompt=prompt_input
        )
        st.write(transcricao)

# MAIN =====================================
def main():
    st.header('Bem-vindo ao Asimov TranscriptüéôÔ∏è', divider=True)
    st.markdown('#### Transcreva √°udio do microfone, de v√≠deos e de arquivos de √°udio')
    tab_mic, tab_video, tab_audio = st.tabs(['Microfone', 'V√≠deo', '√Åudio'])
    with tab_mic:
        transcreve_tab_mic()
    with tab_video:
        transcreve_tab_video()
    with tab_audio:
        transcreve_tab_audio()

if __name__ == '__main__':
    main()
